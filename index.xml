<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jay M. Patel</title>
    <link>http://jaympatel.com/</link>
    <description>Recent content on Jay M. Patel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <copyright>Jay M. Patel</copyright>
    <lastBuildDate>Tue, 29 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://jaympatel.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Detailed Overview of Pandas</title>
      <link>http://jaympatel.com/working-with-pandas/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/working-with-pandas/</guid>
      <description>Introduction This is a first draft of an introductory level tutorial on using Pandas library (versions higher than 0.20) in Python 3.X. We have already covered core Python language in our one hour Python tutorial.
We are also going to stay away from machine learning and data science topics such as natural language processing algorithms etc. but you are encouraged to check out those tutorials by going to the menu and navigating to the tutorial of your choice.</description>
    </item>
    
    <item>
      <title>A Complete Introduction to Python 3.X</title>
      <link>http://jaympatel.com/complete-introduction-to-python/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/complete-introduction-to-python/</guid>
      <description>Introduction This is a first draft of an introductory level tutorial on Python 3.x. It is designed to get a user familiar with core elements of the language in less than one hour without getting bogged down in intricate complexities or edge cases.
This tutorial will NOT cover Numfocus based libraries such as Matplotlib, Numpy, Pandas, scikit-learn, etc. You can check out our Pandas tutorial for more information on Pandas and Numpy.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://jaympatel.com/about/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0530</pubDate>
      
      <guid>http://jaympatel.com/about/</guid>
      <description>My name is Jay M. Patel and I am a fulltime freelance software developer and data scientist specializing in data mining, web crawling/scraping, natural language processing (NLP) projects. Please check out my consulting page for details on how to hire me for your project.
I worked at US Environmental Protection Agency (US EPA) for about five years before quitting in 2018 to do consulting fulltime and bootstrap my startup, Specrom Analytics, which applies AI algorithms for marketing, social listening and creating alternative financial datasets.</description>
    </item>
    
    <item>
      <title>Consulting</title>
      <link>http://jaympatel.com/consulting-services/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/consulting-services/</guid>
      <description>As a full stack software developer and data scientist, my focus is solving problems and getting data driven insights for your business needs.
I can help you evaluate the data you already have, augment and complement it with web scraping/crawling all the while looking out for opportunities to automate and scale so that you can get the answers more rapidly with higher accuracy.
Once I have the data we need, I&amp;rsquo;ll use the most appropriate and state of the art algorithms for a given problem.</description>
    </item>
    
    <item>
      <title>Affiliate Link Policy</title>
      <link>http://jaympatel.com/affiliate-link-policy/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0530</pubDate>
      
      <guid>http://jaympatel.com/affiliate-link-policy/</guid>
      <description>Some articles on jaympatel.com contain links to products available from online retailers. These links may contain codes that signal to the retailer that jaympatel.com has referred you. Should you choose to purchase the product, we may receive a commission on the sale. This is called an affiliate program.
We apply the same rigor and standards of objectivity to these articles as we do to the rest of jaympatel.com’s journalism. Our blog writers, employees or contractors are instructed not to select stories or alter coverage because of this program, and they are not incentivized to do so.</description>
    </item>
    
    <item>
      <title>Books</title>
      <link>http://jaympatel.com/books/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0530</pubDate>
      
      <guid>http://jaympatel.com/books/</guid>
      <description>Disclosure: As an Amazon Associate I earn from qualifying purchases
Getting Structured Data from the Internet: Running Web Crawlers/Scrapers on a Big Data Production Scale ISBN-10: 1484265750
ISBN-13: 978-1484265758
Paperback: Nov 2020
  Apress | Amazon
About the Book
 Shows you how to process web crawls from Common Crawl, one of the largest publicly available web crawl datasets (petabyte scale) indexing over 25 billion web pages ever month.</description>
    </item>
    
    <item>
      <title>Privacy-Policy</title>
      <link>http://jaympatel.com/privacy-policy/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0530</pubDate>
      
      <guid>http://jaympatel.com/privacy-policy/</guid>
      <description>Jaympatel Privacy Policy
This Privacy Policy describes how your personal information is collected, used, and shared when you visit or make a purchase from jaympatel.com (the “Site”).
PERSONAL INFORMATION WE COLLECT
When you visit the Site, we automatically collect certain information about your device, including information about your web browser, IP address, time zone, and some of the cookies that are installed on your device. Additionally, as you browse the Site, we collect information about the individual web pages or products that you view, what websites or search terms referred you to the Site, and information about how you interact with the Site.</description>
    </item>
    
    <item>
      <title>Introduction to machine learning metrics</title>
      <link>http://jaympatel.com/2020/01/introduction-to-machine-learning-metrics/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2020/01/introduction-to-machine-learning-metrics/</guid>
      <description>Machine learning (ML) is a field of computer science that gives computer systems the ability to progressively improve performance on a specific task aka learn with data without being explicitly programmed. Taking a 50,000 ft view, we want to model a given dataset either to make predictions or we want a model to describe a given dataset to gain valuable insights.
There are three general areas of machine learning models</description>
    </item>
    
    <item>
      <title>Introduction to web scraping in python using Beautiful Soup</title>
      <link>http://jaympatel.com/2019/02/introduction-to-web-scraping-in-python-using-beautiful-soup/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/introduction-to-web-scraping-in-python-using-beautiful-soup/</guid>
      <description>The first step for any web scraping project is getting the webpage you want to parse. There are many python libraries such as urllib, urllib2, urllib3 for requesting pages via HTTP, however, none of them beat the elegance of requests library which we have been using in earlier posts on rest APIs and we will continue to use that here. Before we get into the workings of Beautiful Soup, let us first get a basic understanding of HTML structure, common tags and styling sheets.</description>
    </item>
    
    <item>
      <title>Why is web scraping essential and who uses web scraping?</title>
      <link>http://jaympatel.com/2019/02/why-is-web-scraping-essential-and-who-uses-web-scraping/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/why-is-web-scraping-essential-and-who-uses-web-scraping/</guid>
      <description>Web scraping, also called web harvesting, web data extraction, or even web data mining is defined as a software program or code designed to automate the downloading and parsing of the data from the web.
Nowadays many websites such as Twitter, Facebook etc. provides REST based Application Programming Interface (APIs) to programmatically consume the structured data available on their websites and data obtained that way is usually not only &amp;ldquo;cleaner&amp;rdquo; but also easy and hassle-free compared to web scraping.</description>
    </item>
    
    <item>
      <title>Introduction data enrichment based on email addresses and domain names</title>
      <link>http://jaympatel.com/2020/08/introduction-data-enrichment-based-on-email-addresses-and-domain-names/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2020/08/introduction-data-enrichment-based-on-email-addresses-and-domain-names/</guid>
      <description>Data enrichment is a general term to denote any processes which enhance and enrich your existing database with additional information that can be used to drive your business goals such as marketing, sales and lead generation, customer relations by targeted outreach, and preventing customer churn.
Plainly speaking, all you are doing is going out to a third-party data vendor and fetching additional data based on some common key. One of the most keys for data enrichment is searching based on an email address or company&amp;rsquo;s domain address.</description>
    </item>
    
    <item>
      <title>How to do full text searching in Python using Whoosh library</title>
      <link>http://jaympatel.com/2020/08/how-to-do-full-text-searching-in-python-using-whoosh-library/</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2020/08/how-to-do-full-text-searching-in-python-using-whoosh-library/</guid>
      <description>Full text searching with fast indexing is essential to go through large quantities of text in Pandas dataframes to power your data science workflows. Traditionally, we can use a full text search engine databases like Elasticsearch, Apache Solr or Amazon cloudsearch for this; however, it&amp;rsquo;s pretty impractical to do that for one off requirements or when working with only few GBs of data.
In that case, you can simply load your text into Pandas dataframe, and use regex to perform the search as shown.</description>
    </item>
    
    <item>
      <title>How to create pdf documents in python using FPDF library</title>
      <link>http://jaympatel.com/2020/08/how-to-create-pdf-documents-in-python-using-fpdf-library/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2020/08/how-to-create-pdf-documents-in-python-using-fpdf-library/</guid>
      <description>PDF files are ubiquitous in our daily life and it&amp;rsquo;s a good idea to spend few minutes to learn how to programmatically generate it in Python.
In this tutorial, we will take structured data in JSON and convert that into a pdf. Ideally, pdfs contain text paragraphs, hyperlinks and images, so we will work with a dataset containing all of that for better real world experience.
Firstly, let us fetch the data from a publicly available API containing scraped news articles from past 24 hours.</description>
    </item>
    
    <item>
      <title>Introduction to natural language processing: rule based methods, name entity recognition (NER), and text classification</title>
      <link>http://jaympatel.com/2019/02/introduction-to-natural-language-processing-rule-based-methods-name-entity-recognition-ner-and-text-classification/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/introduction-to-natural-language-processing-rule-based-methods-name-entity-recognition-ner-and-text-classification/</guid>
      <description>The ability of computers to understand human languages us referred to as Natural Language Processing (NLP). This is a vast field and frequently practitioners include machine translation and natural language generation (NLG) as part of core NLP. However, in this section we will only look at NLP techniques which aim to extract insights from unstructured text.
Regular expressions (Regex) and rule based methods Regular expressions (Regex) match patterns with sequences of characters and they are supported in wide variety of programming languages.</description>
    </item>
    
    <item>
      <title>Using Twitter rest APIs in Python to search and download tweets in bulk</title>
      <link>http://jaympatel.com/2019/02/using-twitter-rest-apis-in-python-to-search-and-download-tweets-in-bulk/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/using-twitter-rest-apis-in-python-to-search-and-download-tweets-in-bulk/</guid>
      <description>Getting Twitter data Let&amp;rsquo;s use the Tweepy package in python instead of handling the Twitter API directly. The two things we will do with the package are, authorize ourselves to use the API and then use the cursor to access the twitter search APIs.
Let’s go ahead and get our imports loaded.
import tweepy import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import numpy as np sns.</description>
    </item>
    
    <item>
      <title>Natural language processing (NLP): word embeddings, words2vec, GloVe based text vectorization in python</title>
      <link>http://jaympatel.com/2019/02/natural-language-processing-nlp-word-embeddings-words2vec-glove-based-text-vectorization-in-python/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/natural-language-processing-nlp-word-embeddings-words2vec-glove-based-text-vectorization-in-python/</guid>
      <description>In the previous posts, we looked at count vectorization and term frequency-inverse document frequency (tf-idf) to convert a given text document into a vectors which can be used as features for text classification task such as classifying emails into spam or not spam.
Major disadvantages of such an approach is that the vectors generated are sparse (mostly made of zeros), and very high-dimensional (same dimensionality as the number of words in the vocabulary).</description>
    </item>
    
    <item>
      <title>Natural language processing (NLP): text vectorization and bag of words approach</title>
      <link>http://jaympatel.com/2019/02/natural-language-processing-nlp-text-vectorization-and-bag-of-words-approach/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/natural-language-processing-nlp-text-vectorization-and-bag-of-words-approach/</guid>
      <description>Let us consider a simple task of classifying a given email into spam or not spam. As you might have already guessed, this is an example of a simple binary classification problem with target or label values being 0 or 1, within the larger field of supervised machine learning (ML).
However, we still need to convert non-numerical text contained in emails into numerical features which can be fed into a ML algorithm of our choice.</description>
    </item>
    
    <item>
      <title>Natural language processing (NLP): term frequency - inverse document frequency (Tf-idf) based vectorization in Python</title>
      <link>http://jaympatel.com/2019/02/natural-language-processing-nlp-term-frequency-inverse-document-frequency-tf-idf-based-vectorization-in-python/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/natural-language-processing-nlp-term-frequency-inverse-document-frequency-tf-idf-based-vectorization-in-python/</guid>
      <description>In the previous post, we looked at count vectorization to convert a given document into a sparse vectors which can be used as features for text classification task such as classifying emails into spam or not spam.
Count vectorization has one major drawback: it gives equal weightage to all the words (or tokens) present in the corpus, and this makes it a poor representation for the semantic analysis of the sentence.</description>
    </item>
    
    <item>
      <title>Top data science interview questions and answers</title>
      <link>http://jaympatel.com/2019/02/top-data-science-interview-questions-and-answers/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/2019/02/top-data-science-interview-questions-and-answers/</guid>
      <description>Machine learning Basics 1. What is machine learning? Machine learning (ML) is a field of computer science that gives computer systems the ability to progressively improve performance on a specific task aka learn with data without being explicitly programmed. Taking a 50,000 ft view, we want to model a given dataset either to make predictions or we want a model to describe a given dataset to gain valuable insights.</description>
    </item>
    
    <item>
      <title>Get started with Git and Github in under 10 Minutes</title>
      <link>http://jaympatel.com/2018/11/get-started-with-git-and-github-in-under-10-minutes/</link>
      <pubDate>Wed, 28 Nov 2018 08:59:27 +0100</pubDate>
      
      <guid>http://jaympatel.com/2018/11/get-started-with-git-and-github-in-under-10-minutes/</guid>
      <description>Git is probably the most popular version control system being used right now, and if you have any experience with other version control systems like subversion than it&amp;rsquo;s strongly recommended that you go through this section since lot of concepts from other systems don&amp;rsquo;t directly translate to Git.
Git basics You can create a local Git repository on your computer by either:
 Clone an existing Git repository from a remote repository on internet (e.</description>
    </item>
    
    <item>
      <title>CV</title>
      <link>http://jaympatel.com/cv/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://jaympatel.com/cv/</guid>
      <description>jay@jaympatel.com | jaypatel87@gmail.com
LINKEDIN: https://www.linkedin.com/in/jay-m-patel-engg
HOMEPAGE: http://www.jaympatel.com
Click here for latest PDF version
PROFILE:
 Data scientist with over five year&amp;rsquo;s experience in data analytics, machine learning, statistics and text mining.
 I have coauthored 1 book, 10 papers, 26 conference presentations and am passionate about explaining data science to non-technical business audiences.
 Frequent speaker at data science events hosted by Federal community of practice (CoP) as part of DigitalGov initiative.</description>
    </item>
    
  </channel>
</rss>